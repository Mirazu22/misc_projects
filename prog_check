from __future__ import annotations

from pathlib import Path
import pandas as pd


# -----------------------------
# USER INPUTS
# -----------------------------
base_dir_raw = r"C:\...\your\root\folder"  # use r"" for Windows paths with backslashes

start_year = 2015
end_year   = 2020

id_col = "id"

# columns to keep
pred_cols = ["pred_1", "pred_2"]        # <-- predictions in the XLSX (per year)
dummy_cols = ["dummy_a", "dummy_b"]     # <-- dummies in the DTA (time-invariant within id, repeated in long file)

# merge behavior
merge_how = "inner"


# -----------------------------
# PATH BUILDERS
# each year:
# ...\prediction_{year}\unemp\file_unemp_{year}.xlsx
# and a matching dta file (adjust pattern to your real structure)
# -----------------------------
base_dir = Path(base_dir_raw)

def xlsx_path_for_year(year: int) -> Path:
    return base_dir / f"prediction_{year}" / "unemp" / f"file_unemp_{year}.xlsx"

def dta_path_for_year(year: int) -> Path:
    # If your .dta is NOT yearly, see the note below and change this accordingly.
    return base_dir / f"prediction_{year}" / "unemp" / f"file_unemp_{year}.dta"


# -----------------------------
# HELPERS
# -----------------------------
def load_pred_xlsx(year: int) -> pd.DataFrame:
    p = xlsx_path_for_year(year)
    if not p.exists():
        raise FileNotFoundError(f"Missing XLSX for year {year}: {p}")

    df = pd.read_excel(p)

    needed = [id_col] + pred_cols
    missing = [c for c in needed if c not in df.columns]
    if missing:
        raise KeyError(f"{p.name} is missing columns: {missing}\nAvailable: {list(df.columns)}")

    df = df.loc[:, needed].copy()
    df[id_col] = pd.to_numeric(df[id_col], errors="raise").astype("Int64")

    # add year and make year-specific id
    df["year"] = year
    df["id_year"] = df[id_col].astype(str) + "_" + str(year)

    return df


def load_dummies_dta(year: int) -> pd.DataFrame:
    p = dta_path_for_year(year)
    if not p.exists():
        raise FileNotFoundError(f"Missing DTA for year {year}: {p}")

    df = pd.read_stata(p)

    needed = [id_col] + dummy_cols
    missing = [c for c in needed if c not in df.columns]
    if missing:
        raise KeyError(f"{p.name} is missing columns: {missing}\nAvailable: {list(df.columns)}")

    df = df.loc[:, needed].copy()
    df[id_col] = pd.to_numeric(df[id_col], errors="raise").astype("Int64")

    # Check repeated rows per id are identical for dummy columns
    nunique_per_id = df.groupby(id_col, dropna=False)[dummy_cols].nunique(dropna=False)
    bad_ids_mask = (nunique_per_id > 1).any(axis=1)
    if bad_ids_mask.any():
        bad_ids = nunique_per_id.index[bad_ids_mask].tolist()
        example_id = bad_ids[0]
        example_rows = df[df[id_col] == example_id].head(20)
        raise ValueError(
            f"{p.name}: dummy columns vary within id for {len(bad_ids)} ids.\n"
            f"First problematic id: {example_id}\n"
            f"Example rows:\n{example_rows.to_string(index=False)}"
        )

    # Deduplicate to one row per id (time-invariant)
    df = df.sort_values(id_col).drop_duplicates(subset=[id_col], keep="first").copy()

    # Add year and year-specific id, AND year-suffix the dummy column names
    df["year"] = year
    df["id_year"] = df[id_col].astype(str) + "_" + str(year)

    # Rename dummy columns to include year (you asked: dummies need year added)
    df = df.rename(columns={c: f"{c}_{year}" for c in dummy_cols})

    return df


# -----------------------------
# MAIN: loop years, merge per year, then concatenate to long list
# -----------------------------
frames: list[pd.DataFrame] = []

for year in range(start_year, end_year + 1):
    df_pred = load_pred_xlsx(year)
    df_dum  = load_dummies_dta(year)

    merged = df_pred.merge(
        df_dum,
        on=["id_year", "year"],   # year-specific key
        how=merge_how,
        validate="one_to_one"
    )

    # If you want to drop the original id after creating id_year, uncomment:
    # merged = merged.drop(columns=[id_col])

    frames.append(merged)

result_long = pd.concat(frames, ignore_index=True)

print("Years:", start_year, "to", end_year)
print("Result shape:", result_long.shape)
print(result_long.head())


# Optional saves
# out_xlsx = base_dir / f"merged_long_{start_year}_{end_year}.xlsx"
# result_long.to_excel(out_xlsx, index=False)
